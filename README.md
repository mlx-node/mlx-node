<div align="center">

<img src="images/logo.png" alt="MLX-Node Logo" width="150">

<br>
<br>

**High-performance machine learning library for Node.js with GPU acceleration**

<br>

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)
[![Rust](https://img.shields.io/badge/Rust-1.90+-orange.svg)](https://www.rust-lang.org/)

[Quick Start](#quick-start) Â· [Training](#grpo-training) Â· [Training TUI](#training-tui) Â· [Architecture](#architecture) Â· [API Reference](#api-reference) Â· [Documentation](#documentation)

</div>

---

MLX-Node brings Apple's [MLX](https://github.com/ml-explore/mlx) framework to JavaScript/TypeScript, enabling efficient on-device ML inference and training on Apple Silicon and CUDA devices. Built with a Rust compute layer and TypeScript orchestration, it delivers production-ready GRPO training with 100% feature parity with HuggingFace's [TRL](https://github.com/huggingface/trl) library.

<div align="center">
<img src="images/demo.png" alt="MLX-Node Training TUI" width="800">
<br>
<em>Real-time training visualization with the built-in Ratatui TUI</em>
</div>

---

## Why MLX-Node?

| | Feature | Description |
|:--:|:--|:--|
| âš¡ | **Metal GPU Acceleration** | Native Apple Silicon performance via MLX with lazy evaluation and operation fusion |
| ğŸ¯ | **GRPO Training** | Complete reinforcement learning pipeline with 4 loss variants (GRPO, DAPO, Dr.GRPO, BNPO) |
| ğŸ¤– | **Qwen3 Models** | Support for 0.6B, 1.7B, 4B, 8B, 14B, 32B parameter models with advanced sampling |
| ğŸ”„ | **Automatic Differentiation** | Compute gradients through entire models via functional forward pass |
| ğŸš« | **Zero Python Dependency** | Pure Rust/TypeScript implementation â€” no Python runtime required |
| ğŸ“Š | **TypedArray-First API** | Zero-copy operations using native JavaScript typed arrays |

---

## Features at a Glance

<table>
<tr>
<td width="33%" valign="top">

### Model Inference
- Qwen3 (0.6B, 1.7B, 4B, 8B, 14B, 32B)
- Streaming generation [WIP]
- KV cache variants
- Chat templates

</td>
<td width="33%" valign="top">

### GRPO Training
- 4 loss variants
- Custom reward functions
- Gradient accumulation
- Checkpoint resumption

</td>
<td width="33%" valign="top">

### Sampling Strategies
- Temperature scaling
- Top-k / Top-p / Min-p
- Repetition penalty
- XTC sampling

</td>
</tr>
<tr>
<td width="33%" valign="top">

### Neural Network Layers
- Linear, Embedding
- RMSNorm, LayerNorm
- Attention (GQA)
- SwiGLU MLP

</td>
<td width="33%" valign="top">

### Optimizers
- Adam / AdamW
- SGD (with momentum)
- RMSprop
- LR schedulers

</td>
<td width="33%" valign="top">

### Advanced Features
- Autograd integration
- Entropy filtering
- Built-in rewards
- Batch generation

</td>
</tr>
</table>

---

## Quick Start

### Prerequisites

- macOS with Apple Silicon (M1/M2/M3/M4) with Metal (Linux with CUDA is coming soon)
- Node.js 18+
- Rust 1.90

### Build

```bash
git clone https://github.com/mlx-node/mlx-node.git
cd mlx-node
git submodule update --init --recursive
yarn install
yarn build
```

### Download and convert a Model

```bash
yarn download:qwen3
yarn oxnode ./scripts/convert-model.ts --input .cache/models/qwen3-0.6b -d bf16 --output .cache/models/qwen3-0.6b-mlx-bf16
```

### Test the converted model

```bash
yarn oxnode ./examples/test-converted-model.ts
```

### Generate Text

```typescript
import { Qwen3Model } from '@mlx-node/lm';

const model = await Qwen3Model.loadPretrained('.cache/models/qwen3-0.6b-mlx-bf16');

const result = await model.generate(
  [{ role: 'user', content: 'Write a haiku about TypeScript.' }],
  { maxNewTokens: 50, temperature: 0.8 }
);

console.log(result.text);
```

---

## GRPO Training

Train language models using Group Relative Policy Optimization:

```typescript
import { GRPOTrainer, loadLocalGsm8kDataset } from '@mlx-node/trl';

const trainer = await GRPOTrainer.create({
  modelPath: '.cache/models/qwen3-0.6b-mlx-bf16',
  outputDir: 'outputs/my-training',

  // Training hyperparameters
  learningRate: 5e-6,
  batchSize: 4,
  groupSize: 4,
  numEpochs: 3,

  // Generation
  maxNewTokens: 256,
  temperature: 0.8,
  repetitionPenalty: 1.1,

  // GRPO parameters
  clipEpsilon: 0.2,
  klCoef: 0.1,
  lossType: 'grpo',  // or 'dapo', 'dr_grpo', 'bnpo'

  // Custom reward function
  rewardFunction: async (prompts, completions, answers) => {
    return completions.map((completion, i) => {
      const expected = answers[i];
      if (!expected) return 0;
      return completion.includes(expected) ? 1.0 : 0.0;
    });
  },
});

const dataset = await loadLocalGsm8kDataset('.cache/gsm8k', 100);
await trainer.train(dataset);
```

### Built-in Reward Functions

```typescript
// Register multiple reward functions
trainer.registerBuiltinReward({
  rewardType: 'ToolUse',
  allowedTools: ['search', 'calculate'],
  weight: 1.0,
});

trainer.registerBuiltinReward({
  rewardType: 'XmlFormat',
  requiredTags: ['thinking', 'answer'],
  weight: 0.5,
});

trainer.registerBuiltinReward({
  rewardType: 'Length',
  minLength: 100,
  maxLength: 500,
});
```

### Loss Variants

| Variant | Description |
|:--|:--|
| `grpo` | Standard Group Relative Policy Optimization |
| `dapo` | Dynamic Advantage Policy Optimization â€” adaptive clipping |
| `dr_grpo` | Dropout-Regularized GRPO â€” improved stability |
| `bnpo` | Batch-Normalized Policy Optimization â€” normalized advantages |

### Training Examples

```bash
# Quick demo (15-20 minutes)
yarn oxnode examples/grpo/train-simple.ts

# Tool-use training with ast-grep
yarn oxnode examples/grpo/train-tool-use.ts
```

---

## Training TUI

MLX-Node includes a terminal user interface (TUI) built with [Ratatui](https://ratatui.rs/) for real-time training visualization and control.

<div align="center">
<img src="images/demo.png" alt="MLX-Node Training TUI" width="800">
</div>

### Building the TUI

### Running Training with TUI

```bash
# Basic usage
cargo run -p mlx-tui -- --import '@oxc-node/core/register' --script ./examples/grpo/train-tool-use.ts
```

The TUI wraps your Node.js training script and communicates via stdout (JSONL messages) and stdin (control commands).

### TUI Features

| Panel | Description |
|:--|:--|
| **Header** | Model name, epoch/step progress, training status |
| **Metrics** | Loss, reward, and advantage with sparkline history |
| **Progress** | Epoch and step progress bars with percentages |
| **Stats** | Token count, elapsed time, step speed breakdown |
| **Logs** | Real-time training logs (scrollable) |
| **Samples** | Generated samples with rewards (best/worst/latest modes) |
| **Config** | Current training configuration |

### Keyboard Controls

| Key | Action |
|:--|:--|
| `p` | Pause training |
| `r` | Resume training |
| `s` | Save checkpoint |
| `Tab` | Switch between tabs (Logs/Samples/Config) |
| `â†‘` `â†“` | Scroll within current tab |
| `m` | Cycle sample display mode (Best â†’ Worst â†’ Latest) |
| `?` | Toggle help overlay |
| `q` | Quit TUI |

### Enabling TUI Mode in Training Scripts

To make your training script compatible with the TUI, enable `tuiMode` in the trainer:

```typescript
import { GRPOTrainer } from '@mlx-node/trl';

const trainer = await GRPOTrainer.create({
  modelPath: '.cache/models/qwen3-0.6b-mlx-bf16',
  outputDir: 'outputs/training',
  tuiMode: true,  // Enable TUI-compatible output
  // ... other options
});
```

When `tuiMode` is enabled:
- All logging output uses JSONL format for TUI parsing
- The trainer listens for stdin commands (pause, resume, save)
- Progress updates are sent as structured messages

### TUI Message Protocol

The TUI communicates with training scripts via a simple protocol:

**Training â†’ TUI** (stdout, JSONL):
```json
{"type": "step", "epoch": 1, "step": 10, "loss": 0.5, "reward": 4.2}
{"type": "log", "level": "info", "message": "Starting epoch 2"}
{"type": "sample", "prompt": "...", "completion": "...", "reward": 5.0}
```

**TUI â†’ Training** (stdin, line commands):
```
pause
resume
save
```

---

## Architecture

MLX-Node uses a clean two-layer architecture: **Rust for compute**, **TypeScript for orchestration**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TypeScript Orchestration Layer                       â”‚
â”‚                          (2,528 lines)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  @mlx-node/lm   â”‚  â”‚  @mlx-node/trl  â”‚  â”‚ @mlx-node/core  â”‚           â”‚
â”‚  â”‚  Model loading  â”‚  â”‚  GRPO Trainer   â”‚  â”‚  (internal)     â”‚           â”‚
â”‚  â”‚  Generation     â”‚  â”‚  Rewards        â”‚  â”‚  NAPI bindings  â”‚           â”‚
â”‚  â”‚  Configs        â”‚  â”‚  Datasets       â”‚  â”‚  Type exports   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                       NAPI-RS Bridge (344 exports)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        Rust Compute Layer                                â”‚
â”‚                         (15,052+ lines)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   array/     â”‚ â”‚ transformer/ â”‚ â”‚   grpo/      â”‚ â”‚  optimizers/ â”‚     â”‚
â”‚  â”‚  90+ ops     â”‚ â”‚  Attention   â”‚ â”‚  Loss        â”‚ â”‚  Adam(W)     â”‚     â”‚
â”‚  â”‚  Masking     â”‚ â”‚  KVCache     â”‚ â”‚  Advantages  â”‚ â”‚  SGD         â”‚     â”‚
â”‚  â”‚  Padding     â”‚ â”‚  MLP         â”‚ â”‚  Autograd    â”‚ â”‚  RMSprop     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   nn/        â”‚ â”‚ models/qwen3 â”‚ â”‚  sampling    â”‚ â”‚  tokenizer   â”‚     â”‚
â”‚  â”‚  Linear      â”‚ â”‚  Forward     â”‚ â”‚  Top-k/p     â”‚ â”‚  HuggingFace â”‚     â”‚
â”‚  â”‚  RMSNorm     â”‚ â”‚  Generation  â”‚ â”‚  Min-p, XTC  â”‚ â”‚  Chat        â”‚     â”‚
â”‚  â”‚  Embedding   â”‚ â”‚  Persistence â”‚ â”‚  Rep. Pen.   â”‚ â”‚  Templates   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     mlx-sys FFI + C++ Bridge                             â”‚
â”‚                       (683 + 3,732 lines)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  MLX Library + Metal GPU Backend                         â”‚
â”‚              Lazy evaluation Â· Operation fusion Â· GPU kernels            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Package Overview

| Package | Purpose | Use For |
|:--|:--|:--|
| `@mlx-node/lm` | Model loading & inference | Loading models, generating text, model configs |
| `@mlx-node/trl` | Training & optimization | GRPO training, custom rewards, optimizers |
| `@mlx-node/core` | Native bindings (internal) | Low-level operations (usually import via lm/trl) |

### Import Patterns

```typescript
// For inference
import { Qwen3Model, Qwen3Tokenizer, QWEN3_CONFIGS, ModelLoader } from '@mlx-node/lm';

// For training
import {
  GRPOTrainer, GRPOConfig,
  Adam, AdamW, SGD, RMSprop,
  loadLocalGsm8kDataset,
  correctnessReward, strictFormatReward,
} from '@mlx-node/trl';

// For low-level operations (via trl re-exports)
import {
  MxArray, Linear, RMSNorm, Attention, TransformerBlock,
  KVCache, BatchKVCache, RotatingKVCache,
  Activations, Losses, Gradients,
} from '@mlx-node/trl';
```

---

## API Reference

### Model Loading & Generation

```typescript
import { Qwen3Model } from '@mlx-node/lm';

// Load a model
const model = await Qwen3Model.loadPretrained(modelPath);

// Generate with full sampling options
const result = await model.generate(messages, {
  maxNewTokens: 256,
  temperature: 0.8,
  topK: 50,
  topP: 0.95,
  minP: 0.05,
  repetitionPenalty: 1.1,
  xtcThreshold: 0.1,
  xtcProbability: 0.5,
});

console.log(result.text);
console.log(`Generated ${result.tokenCount} tokens`);

// Save fine-tuned model
await model.saveModel('outputs/fine-tuned');
```

### Sampling Strategies

| Strategy | Parameter | Description |
|:--|:--|:--|
| Temperature | `temperature: 0.8` | Controls randomness (lower = more focused) |
| Top-K | `topK: 50` | Keep top K most likely tokens |
| Top-P (Nucleus) | `topP: 0.95` | Cumulative probability threshold |
| Min-P | `minP: 0.05` | Minimum probability relative to max |
| Repetition Penalty | `repetitionPenalty: 1.2` | Reduce repetitive text |
| XTC | `xtcThreshold: 0.1` | eXclude Top Choices (stochastic) |

### Low-Level Operations

```typescript
import { MxArray, Linear, RMSNorm, Activations } from '@mlx-node/trl';

// Create arrays using TypedArrays
const x = MxArray.fromFloat32(
  new Float32Array([1, 2, 3, 4, 5, 6]),
  BigInt64Array.from([2n, 3n])  // shape: [2, 3]
);

// Matrix operations
const y = x.matmul(weights);
const sum = x.sum();
const mean = x.mean(0);  // Along axis 0

// Neural network layers
const linear = new Linear(512, 1024);
const norm = new RMSNorm(1024, 1e-5);

let h = linear.forward(input);
h = norm.forward(h);
h = Activations.silu(h);
```

### KV Cache Options

```typescript
import { KVCache, BatchKVCache, RotatingKVCache } from '@mlx-node/trl';

// Standard cache for single sequences
const cache = new KVCache();

// Batch cache for variable-length sequences with left-padding
const batchCache = new BatchKVCache([1, 2, 0]);  // Padding per sequence
const [keys, values] = batchCache.updateAndFetch(newKeys, newValues);
batchCache.filter([0, 2]);  // Keep only certain sequences

// Rotating cache for bounded memory
const rotatingCache = new RotatingKVCache({ maxSize: 2048, keep: 128 });
```

---

### Optimizations

- **Zero-copy TypedArray operations** â€” Direct memory access without serialization
- **Lazy evaluation** â€” Operations are traced and fused before execution
- **Fused kernels** â€” Combined attention, MLP, and transformer blocks in C++
- **Rust training loop** â€” Fast!
- **Thread-safe handles** â€” `Arc<MxHandle>` for safe multi-threaded access
- **Memory-efficient caching** â€” Standard, Batch, and Rotating KV cache options

---

## Development

```bash
# Build
yarn build              # Release build (native + TypeScript)
yarn build:debug        # Debug build
yarn build:native       # Native addon only
yarn build:ts           # TypeScript packages only

# Test
yarn test               # All tests (except trainers)
TEST_TRAINER=1 yarn test  # Include trainer tests (sequential)
yarn vitest run <path>  # Specific test file

# Quality
yarn typecheck          # TypeScript validation
yarn lint               # Linting with oxlint
```

### Project Structure

```
mlx-node/
â”œâ”€â”€ crates/                     # Rust workspace
â”‚   â”œâ”€â”€ mlx-sys/                # Low-level MLX bindings + C++ bridge
â”‚   â”‚   â”œâ”€â”€ src/lib.rs          # FFI bindings (683 lines)
â”‚   â”‚   â””â”€â”€ src/mlx.cpp         # C++ bridge (3,732 lines)
â”‚   â””â”€â”€ mlx-core/               # All NAPI exports
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ array/          # Tensor operations
â”‚           â”œâ”€â”€ nn/             # Neural network layers
â”‚           â”œâ”€â”€ transformer/    # Attention, caches, blocks
â”‚           â”œâ”€â”€ models/qwen3/   # Qwen3 implementation
â”‚           â”œâ”€â”€ grpo/           # Training components
â”‚           â”œâ”€â”€ optimizers/     # Adam, SGD, RMSprop
â”‚           â””â”€â”€ sampling.rs     # Generation strategies
â”œâ”€â”€ packages/                   # npm workspace
â”‚   â”œâ”€â”€ core/                   # @mlx-node/core (native addon)
â”‚   â”œâ”€â”€ lm/                     # @mlx-node/lm (inference API)
â”‚   â””â”€â”€ trl/                    # @mlx-node/trl (training API)
â”œâ”€â”€ examples/grpo/              # Training examples
â””â”€â”€ __test__/                   # Test suite (20,211 lines)
```

---

## Project Status

| Phase | Status | Description |
|:--|:--|:--|
| Core Operations | âœ… Complete | 90+ array/tensor operations |
| Neural Networks | âœ… Complete | Layers, activations, losses |
| Gradients | âœ… Complete | Manual + automatic differentiation |
| Transformers | âœ… Complete | Attention, KVCache variants, MLP |
| GRPO Training | âœ… Complete | Production-ready with 4 loss variants |
| Autograd | âœ… Complete | Functional forward pass architecture |

**Test Coverage:** 1,036/1,039 tests passing (100%)

---

## Documentation

- [GRPO Training Guide](docs/grpo/README.md)
- [Autograd Integration](docs/AUTOGRAD_INTEGRATION.md)
- [Feature Alignment](docs/FEATURE_ALIGNMENT_SESSION.md)
- [Causal Mask Fix](docs/causal-mask-bug-fix.md)
- [Development History](docs/DEVELOPMENT_HISTORY.md)
- [SafeTensors Loader](docs/SAFETENSORS_LOADER.md)

---

## References

- [MLX Documentation](https://ml-explore.github.io/mlx/) â€” Apple's ML framework
- [GRPO Paper](https://arxiv.org/abs/2402.03300) â€” Group Relative Policy Optimization
- [TRL Library](https://github.com/huggingface/trl) â€” HuggingFace training library
- [Qwen3 Models](https://huggingface.co/Qwen) â€” Model weights
- [NAPI-RS](https://napi.rs/) â€” Rust Node.js bindings

---

## License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## Acknowledgments

- [Apple MLX Team](https://github.com/ml-explore/mlx) for the ML framework
- [HuggingFace TRL](https://github.com/huggingface/trl) for GRPO reference implementation
- [NAPI-RS](https://napi.rs/) for seamless Node.js bindings
- [Qwen Team](https://huggingface.co/Qwen) for the model architecture

---

<div align="center">

**[Back to top](#mlx-node)**

</div>
